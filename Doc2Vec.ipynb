{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "import pyprind\n",
    "import os\n",
    "import multiprocessing\n",
    "import requests\n",
    "import pprint\n",
    "\n",
    "import gensim as gs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from gensim.models.doc2vec import Doc2Vec\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from gensim.utils import to_unicode\n",
    "from gensim.utils import tokenize\n",
    "from collections import namedtuple\n",
    "from collections import OrderedDict\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cores = multiprocessing.cpu_count()\n",
    "dirname = 'aclImdb'\n",
    "filename = 'aclImdb_v1.tar.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_extract_data(dirname, filename):\n",
    "    if not os.path.isfile('aclImdb/alldata-id.txt'):\n",
    "        if not os.path.isdir(dirname):\n",
    "            if not os.path.isfile(filename):\n",
    "                print(\"Downloading IMDB archive...\")\n",
    "                url = u'http://ai.stanford.edu/~amaas/data/sentiment/' + filename\n",
    "                r = requests.get(url)\n",
    "                with open(filename, 'wb') as f:\n",
    "                    f.write(r.content)\n",
    "            tar = tarfile.open(filename, mode='r')\n",
    "            tar.extractall()\n",
    "            tar.close()\n",
    "            print(\"Data extracted...\")\n",
    "            \n",
    "def normalize(text):\n",
    "    punctuations = ['<br /><br />']\n",
    "    \n",
    "    for punctuation in punctuations:\n",
    "        text = text.replace(punctuation, \"\")\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download_extract_data(dirname, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [##############################] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:10:38\n"
     ]
    }
   ],
   "source": [
    "dirname = 'aclImdb'\n",
    "labels = {'pos' : 1, 'neg' : 0, 'unsup' : -1}\n",
    "pbar = pyprind.ProgBar(100000)\n",
    "df = pd.DataFrame()\n",
    "\n",
    "for s in ('test', 'train'):       \n",
    "    for l in ('pos', 'neg', 'unsup'):\n",
    "        path = os.path.join(dirname, s, l)\n",
    "      \n",
    "        if s=='test' and l=='unsup':\n",
    "            break\n",
    "        \n",
    "        for file in os.listdir(path):\n",
    "            with open(os.path.join(path, file), 'r', encoding = 'utf-8') as infile:\n",
    "                txt = to_unicode(infile.read())\n",
    "                txt = normalize(txt)\n",
    "                txt = list(tokenize(txt))\n",
    "                df = df.append([[txt, labels[l], l]], ignore_index=True)\n",
    "            pbar.update() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>label</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[I, ve, seen, the, movie, Lost, Horizons, and,...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[This, short, deals, with, a, severely, critic...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[this, is, one, of, the, finest, movies, i, ha...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Are, You, in, the, House, Alone, belongs, to,...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[I, saw, this, movie, in, Santa, Monica, on, A...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               token  label  tags\n",
       "0  [I, ve, seen, the, movie, Lost, Horizons, and,...      1     0\n",
       "1  [This, short, deals, with, a, severely, critic...      1     1\n",
       "2  [this, is, one, of, the, finest, movies, i, ha...      1     2\n",
       "3  [Are, You, in, the, House, Alone, belongs, to,...      1     3\n",
       "4  [I, saw, this, movie, in, Santa, Monica, on, A...      1     4"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns=['token', 'label', 'tags']\n",
    "df['tags'] = df.index\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sentences = list(zip(df['token'].values, df['tags'].values))\n",
    "taggeddoc = []\n",
    "for i,item in enumerate(sentences):\n",
    "    td = TaggedDocument(words = item[0], tags = [str(item[1])])\n",
    "    taggeddoc.append(td)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocabulary built\n"
     ]
    }
   ],
   "source": [
    "model_dm = Doc2Vec(size = 400, window = 10, min_count = 1, workers = 6, \n",
    "                alpha = 0.025, min_alpha = 0.0050, sample = 1e-4, negative = 5, dm=1)\n",
    "model_dbow = Doc2Vec(size = 400, window = 10, min_count = 1, workers = 6, \n",
    "                alpha = 0.025, min_alpha = 0.0050, sample = 1e-4, negative = 5, dm=0)\n",
    "\n",
    "model_dm.build_vocab(taggeddoc)\n",
    "model_dbow.build_vocab(taggeddoc)\n",
    "\n",
    "print('vocabulary built')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0\n",
      "epoch:  1\n",
      "epoch:  2\n",
      "epoch:  3\n",
      "epoch:  4\n",
      "epoch:  5\n",
      "epoch:  6\n",
      "epoch:  7\n",
      "epoch:  8\n",
      "epoch:  9\n",
      "epoch:  10\n",
      "epoch:  11\n",
      "epoch:  12\n",
      "epoch:  13\n",
      "epoch:  14\n",
      "epoch:  15\n",
      "epoch:  16\n",
      "epoch:  17\n",
      "epoch:  18\n",
      "epoch:  19\n",
      "models trained\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(20):\n",
    "    print(\"epoch: \", epoch)\n",
    "    model_dm.train(taggeddoc, total_examples=model_dm.corpus_count, epochs = model_dm.iter)    \n",
    "    model_dbow.train(taggeddoc, total_examples=model_dbow.corpus_count, epochs = model_dbow.iter)    \n",
    "    \n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        model_dm.save('./imdb_dm.d2v')\n",
    "        model_dbow.save('./imdb_dbow.d2v')        \n",
    "\n",
    "print('models trained')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DM\n",
      "[('wonderful', 0.5328915119171143),\n",
      " ('superb', 0.5063442587852478),\n",
      " ('terrible', 0.4888131022453308),\n",
      " ('fantastic', 0.48425111174583435),\n",
      " ('terrific', 0.47444143891334534),\n",
      " ('great', 0.47082194685935974),\n",
      " ('excellent', 0.45563891530036926),\n",
      " ('horrible', 0.43797510862350464),\n",
      " ('amazing', 0.4295591115951538),\n",
      " ('fine', 0.41918909549713135)]\n",
      "DBOW\n",
      "[('orinirique', 0.2208365797996521),\n",
      " ('Straights', 0.22082586586475372),\n",
      " ('uomo', 0.21756674349308014),\n",
      " ('Melbournehes', 0.2153024524450302),\n",
      " ('Repentful', 0.2029258757829666),\n",
      " ('kidnappable', 0.20245155692100525),\n",
      " ('repulse', 0.20046527683734894),\n",
      " ('Acolytes', 0.2001710683107376),\n",
      " ('trope', 0.19949795305728912),\n",
      " ('communities', 0.1984124779701233)]\n",
      "***************************************************************************\n",
      "DM\n",
      "[('funny', 0.3479025363922119),\n",
      " ('witty', 0.3396616280078888),\n",
      " ('intelligent', 0.339173287153244),\n",
      " ('weak', 0.3217778205871582),\n",
      " ('bad', 0.31999388337135315),\n",
      " ('stupid', 0.31319567561149597),\n",
      " ('smart', 0.3052785098552704),\n",
      " ('provoking', 0.29966843128204346),\n",
      " ('cool', 0.2961874008178711),\n",
      " ('good', 0.2957375943660736)]\n",
      "DBOW\n",
      "[('Pukara', 0.24673712253570557),\n",
      " ('Gylenhall', 0.24222373962402344),\n",
      " ('resurgence', 0.2094532698392868),\n",
      " ('sibilized', 0.20421460270881653),\n",
      " ('Jacobe', 0.2034478485584259),\n",
      " ('Travants', 0.202455073595047),\n",
      " ('Lollars', 0.19865058362483978),\n",
      " ('quakers', 0.1981111764907837),\n",
      " ('Brozana', 0.19361375272274017),\n",
      " ('StarGate', 0.19217421114444733)]\n",
      "***************************************************************************\n",
      "DM\n",
      "[('dumb', 0.503750205039978),\n",
      " ('bad', 0.44821202754974365),\n",
      " ('silly', 0.43364042043685913),\n",
      " ('horrible', 0.4127037525177002),\n",
      " ('ridiculous', 0.4103361666202545),\n",
      " ('awful', 0.36581480503082275),\n",
      " ('lame', 0.363579660654068),\n",
      " ('annoying', 0.35361015796661377),\n",
      " ('predictable', 0.3478536605834961),\n",
      " ('terrible', 0.34767261147499084)]\n",
      "DBOW\n",
      "[('installment', 0.23375515639781952),\n",
      " ('wayward', 0.23369668424129486),\n",
      " ('Tiriel', 0.20682376623153687),\n",
      " ('wildcard', 0.20647065341472626),\n",
      " ('diarrhoea', 0.20261313021183014),\n",
      " ('HSD', 0.20105576515197754),\n",
      " ('caudillos', 0.19848164916038513),\n",
      " ('Scandal', 0.1928900182247162),\n",
      " ('Kaidan', 0.1924809217453003),\n",
      " ('blackened', 0.19241227209568024)]\n",
      "***************************************************************************\n"
     ]
    }
   ],
   "source": [
    "for word in ['brilliant', 'clever', 'stupid']:\n",
    "    print('DM')\n",
    "    pprint.pprint(model_dm.wv.most_similar(word))\n",
    "    print('DBOW')\n",
    "    pprint.pprint(model_dbow.wv.most_similar(word))\n",
    "    print('*'*75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['label']!=-1]\n",
    "tags = df['tags'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_raw = np.zeros((50000, 800))\n",
    "\n",
    "for i in tags:\n",
    "    X_raw[i] = np.hstack([model_dm.docvecs[str(i)], model_dbow.docvecs[str(i)]])\n",
    "\n",
    "y_raw = df['label'].values\n",
    "target_names = ['positive', 'negative']\n",
    "X_raw_train, X_test, y_raw_train, y_test = train_test_split(X_raw, y_raw, test_size = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X_raw_train, y_raw_train, n_splits, clf):\n",
    "\n",
    "    kfold = sk.model_selection.StratifiedKFold(n_splits=n_splits, random_state=101).split(X= X_raw_train, y=y_raw_train)\n",
    "    for i, (train_idx, valid_idx) in enumerate(kfold):\n",
    "        X_train, y_train = X_raw_train[train_idx, :], y_raw_train[train_idx]    \n",
    "        X_valid, y_valid = X_raw_train[valid_idx, :], y_raw_train[valid_idx]    \n",
    "\n",
    "        clf.fit(X_train, y_train)    \n",
    "        score_train = clf.score(X_train, y_train)\n",
    "        score_valid = clf.score(X_valid, y_valid)\n",
    "        print('Validation- Train: {:.4f} Test: {:.4f}'.format(score_train, score_valid)) \n",
    "\n",
    "    clf.fit(X_raw_train, y_raw_train)\n",
    "    score_train = clf.score(X_raw_train, y_raw_train)\n",
    "    score_test = clf.score(X_test, y_test)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    print()\n",
    "    print('Final- Train: {:.4f} Test: {:.4f}'.format(score_train, score_test)) \n",
    "    print()\n",
    "    print(classification_report(y_test, y_pred, target_names=target_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation- Train: 0.9245 Test: 0.9050\n",
      "Validation- Train: 0.9247 Test: 0.9092\n",
      "Validation- Train: 0.9251 Test: 0.9024\n",
      "Validation- Train: 0.9247 Test: 0.9072\n",
      "Validation- Train: 0.9249 Test: 0.9080\n",
      "\n",
      "Final- Train: 0.9226 Test: 0.9082\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   positive       0.91      0.91      0.91     12484\n",
      "   negative       0.91      0.91      0.91     12516\n",
      "\n",
      "avg / total       0.91      0.91      0.91     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr_clf = LogisticRegression(C=1.0, fit_intercept=True, intercept_scaling=1, \n",
    "                                 penalty='l2', random_state=101, tol=1e-5)\n",
    "train(X_raw_train, y_raw_train, 5, lr_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation- Train: 0.9695 Test: 0.8644\n",
      "Validation- Train: 0.9690 Test: 0.8732\n",
      "Validation- Train: 0.9703 Test: 0.8698\n",
      "Validation- Train: 0.9695 Test: 0.8684\n",
      "Validation- Train: 0.9699 Test: 0.8734\n",
      "\n",
      "Final- Train: 0.9714 Test: 0.8802\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   positive       0.88      0.88      0.88     12484\n",
      "   negative       0.88      0.88      0.88     12516\n",
      "\n",
      "avg / total       0.88      0.88      0.88     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm_clf = SVC(C=1.0, kernel='rbf')\n",
    "train(X_raw_train, y_raw_train, 5, svm_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
